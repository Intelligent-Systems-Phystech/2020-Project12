\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\title
%    [Обучение машинного перевода без параллельных текстов] % Краткое название; не нужно, если полное название влезает в~колонтитул
{Обучение машинного перевода без параллельных текстов}
\author
%    [Ямалутдинов~А.\,В.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
{Ямалутдинов~А.\,В.,  Стрижов~В.\,В., Бахтеев~О.\,Ю.} % основной список авторов, выводимый в оглавление
[Ямалутдинов~А.\,В.,  Стрижов~В.\,В., Бахтеев~О.\,Ю.$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
%    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
%   Научный руководитель:  Стрижов~В.\,В.
{Задачу поставил:  Стрижов~В.\,В.
	 Консультант:  Бахтеев~О.\,Ю.}
\email
{yamalutdinov.av@phystech.ru, strijov@ccas.ru, bakhteev@phystech.edu}
\organization
{$^1$ Московский физико-технический институт, Москва, Россия}%; $^2$Организация}
\abstract
{
    В данной работе исследуется метод обучения без учителя для задачи машинного перевода. Рассматривается подход, основанный
    на автокодировщиках: каждое предложение отображается кодировщиком в вектор в латентном пространстве, а декодировщик восстанавливает
    полученный вектор в предложение на другом языке. Оптимизация моделей проводится таким образом, чтобы скрытые пространства 
    автокодировщиков для разных языков совпадали. В качестве исходного представления предложений предлагается рассматривать 
    их графовое описание, получаемое с использованием мультиязычных онтологий.
    \bigskip
    
	\textbf{Ключевые слова}: \emph {машинный перевод, автокодировщики, нейронные сети}.}
\titleEng
{JMLDA paper example: file jmlda-example.tex}
\authorEng
{Author~F.\,S.$^1$, CoAuthor~F.\,S.$^2$, Name~F.\,S.$^2$}
\organizationEng
{$^1$Organization; $^2$Organization}
\abstractEng
{This document is an example of paper prepared with \LaTeXe\
	typesetting system and style file \texttt{jmlda.sty}.
	
	\bigskip
	\textbf{Keywords}: \emph{keyword, keyword, more keywords}.}
\begin{document}
	
	\maketitle
	
	\section{Введение}
    В последнее время наблюдаются значительные успехи в решении задачи машинного перевода, главным образом за счет использования 
    глубоких нейронных сетей. Основным недостатком такого подходя является тот факт, что для обучения таких сетей требуется огромное
    (около миллиона) количество параллельных предложений. Это требование значительно ограничивает возможности построения моделей для
    низкоресурсных языков (т.е. языков, для которых данных в открытом доступе немного).

    Исследуется возможность решения задачи машинного перевода как задачи обучения без учителя. В таком случае нет необходимости в
    большом количестве параллельных предложений, для обучения модели достаточно иметь выборку предложений на каждом из языков. 
	
	%\begin{State}
	%    Мотивации и~интерпретации наиболее важны для понимания сути работы.
	%\end{State}
	
	%\begin{Theorem}
	%    Не~менее $90\%$ коллег, заинтересовавшихся Вашей статьёй,
	%    прочитают в~ней не~более~$10\%$ текста.
	%\end{Theorem}
	%
	%\begin{Proof}
	%    Причём это будут именно те~разделы, которые не содержат формул.
	%\end{Proof}
	%
	%\begin{Remark}
	%    Выше показано применение окружений
	%    Def, Theorem, State, Remark, Proof.
	%\end{Remark}
	
	
	%\section{Заключение}
	
	%Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
	%Обычно здесь отмечают,
	%каких результатов удалось добиться,
	%какие проблемы остались открытыми.
	
	
	\bibliographystyle{plain}
	\bibliography{Mamonov2020Project73}
	
	% Решение Программного Комитета:
	%\ACCEPTNOTE
	%\AMENDNOTE
	%\REJECTNOTE
\end{document}